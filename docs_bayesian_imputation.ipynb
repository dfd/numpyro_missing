{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "I got this notebook from the numpyro documentation and edited to demonstrate a problem I'm having with imputing missing data to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world datasets often contain many missing values. In those situations, we have to either remove those missing data (also known as \"complete case\") or replace them by some values. Though using complete case is pretty straightforward, it is only applicable when the number of missing entries is so small that throwing away those entries would not affect much the power of the analysis we are conducting on the data. The second strategy, also known as [imputation](https://en.wikipedia.org/wiki/Imputation_%28statistics%29), is more applicable and will be our focus in this tutorial.\n",
    "\n",
    "Probably the most popular way to perform imputation is to fill a missing value with the mean, median, or mode of its corresponding feature. In that case, we implicitly assume that the feature containing missing values has no correlation with the remaining features of our dataset. This is a pretty strong assumption and might not be true in general. In addition, it does not encode any uncertainty that we might put on those values. Below, we will construct a *Bayesian* setting to resolve those issues. In particular, given a model on the dataset, we will\n",
    "\n",
    "+ create a generative model for the feature with missing value\n",
    "+ and consider missing values as unobserved latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q numpyro@git+https://github.com/pyro-ppl/numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need some imports\n",
    "import os\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "from numpyro.distributions import constraints\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "if \"NUMPYRO_SPHINXBUILD\" in os.environ:\n",
    "    set_matplotlib_formats(\"svg\")\n",
    "\n",
    "assert numpyro.__version__.startswith(\"0.9.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken from the competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) hosted on [kaggle](https://www.kaggle.com/). It contains information of passengers in the [Titanic accident](https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Titanic) such as name, age, gender,... And our target is to predict if a person is more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv\"\n",
    ")\n",
    "train_df.info()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data info, we know that there are missing data at `Age`, `Cabin`, and `Embarked` columns. Although `Cabin` is an important feature (because the position of a cabin in the ship can affect the chance of people in that cabin to survive), we will skip it in this tutorial for simplicity. In the dataset, there are many categorical columns and two numerical columns `Age` and `Fare`. Let's first look at the distribution of those categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n",
      "\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n",
      "\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]:\n",
    "    print(train_df[col].value_counts(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will merge rare groups in `SibSp` and `Parch` columns together. In addition, we'll fill 2 missing entries in `Embarked` by the mode `S`. Note that we can make a generative model for those missing entries in `Embarked` but let's skip doing so for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.SibSp.clip(0, 1, inplace=True)\n",
    "train_df.Parch.clip(0, 2, inplace=True)\n",
    "train_df.Embarked.fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closer at the data, we can observe that each name contains a title. We know that age is correlated with the title of the name: e.g. those with Mrs. would be older than those with `Miss.` (on average) so it might be good to create that feature. The distribution of titles is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.          517\n",
       "Miss.        182\n",
       "Mrs.         125\n",
       "Master.       40\n",
       "Dr.            7\n",
       "Rev.           6\n",
       "Mlle.          2\n",
       "Major.         2\n",
       "Col.           2\n",
       "the            1\n",
       "Capt.          1\n",
       "Ms.            1\n",
       "Sir.           1\n",
       "Lady.          1\n",
       "Mme.           1\n",
       "Don.           1\n",
       "Jonkheer.      1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a new column `Title`, where rare titles are merged into one group `Misc.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Title\"] = (\n",
    "    train_df.Name.str.split(\", \")\n",
    "    .str.get(1)\n",
    "    .str.split(\" \")\n",
    "    .str.get(0)\n",
    "    .apply(lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is ready to turn the dataframe, which includes categorical values, into numpy arrays. We also perform standardization (a good practice for regression models) for `Age` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cat = pd.CategoricalDtype(\n",
    "    categories=[\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\", \"Misc.\"], ordered=True\n",
    ")\n",
    "embarked_cat = pd.CategoricalDtype(categories=[\"S\", \"C\", \"Q\"], ordered=True)\n",
    "age_mean, age_std = train_df.Age.mean(), train_df.Age.std()\n",
    "data = dict(\n",
    "    age=train_df.Age.pipe(lambda x: (x - age_mean) / age_std).values,\n",
    "    pclass=train_df.Pclass.values - 1,\n",
    "    title=train_df.Title.astype(title_cat).cat.codes.values,\n",
    "    sex=(train_df.Sex == \"male\").astype(int).values,\n",
    "    sibsp=train_df.SibSp.values,\n",
    "    parch=train_df.Parch.values,\n",
    "    embarked=train_df.Embarked.astype(embarked_cat).cat.codes.values,\n",
    ")\n",
    "survived = train_df.Survived.values\n",
    "# compute the age mean for each title\n",
    "age_notnan = data[\"age\"][jnp.isfinite(data[\"age\"])]\n",
    "title_notnan = data[\"title\"][jnp.isfinite(data[\"age\"])]\n",
    "age_mean_by_title = jnp.stack([age_notnan[title_notnan == i].mean() for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to note that in NumPyro, the following models\n",
    "```python\n",
    "def model1a():\n",
    "    x = numpyro.sample(\"x\", dist.Normal(0, 1).expand([10]))\n",
    "```\n",
    "and\n",
    "```python\n",
    "def model1b():\n",
    "    x = numpyro.sample(\"x\", dist.Normal(0, 1).expand([10]).mask(False))\n",
    "    numpyro.sample(\"x_obs\", dist.Normal(0, 1).expand([10]), obs=x)\n",
    "```\n",
    "are equivalent in the sense that both of them have\n",
    "\n",
    "+ the same latent sites `x` drawn from `dist.Normal(0, 1)` prior,\n",
    "+ and the same log densities `dist.Normal(0, 1).log_prob(x)`.\n",
    "\n",
    "Now, assume that we observed the last 6 values of `x` (non-observed entries take value `NaN`), the typical model will be\n",
    "```python\n",
    "def model2a(x):\n",
    "    x_impute = numpyro.sample(\"x_impute\", dist.Normal(0, 1).expand([4]))\n",
    "    x_obs = numpyro.sample(\"x_obs\", dist.Normal(0, 1).expand([6]), obs=x[4:])\n",
    "    x_imputed = jnp.concatenate([x_impute, x_obs])\n",
    "```\n",
    "or with the usage of `mask`,\n",
    "```python\n",
    "def model2b(x):\n",
    "    x_impute = numpyro.sample(\"x_impute\", dist.Normal(0, 1).expand([4]).mask(False))\n",
    "    x_imputed = jnp.concatenate([x_impute, x[4:]])\n",
    "    numpyro.sample(\"x\", dist.Normal(0, 1).expand([10]), obs=x_imputed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both approaches to model the partial observed data `x` are equivalent. For the model below, we will use the latter method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    age, pclass, title, sex, sibsp, parch, embarked, survived=None, bayesian_impute=True\n",
    "):\n",
    "    b_pclass = numpyro.sample(\"b_Pclass\", dist.Normal(0, 1).expand([3]))\n",
    "    b_title = numpyro.sample(\"b_Title\", dist.Normal(0, 1).expand([5]))\n",
    "    b_sex = numpyro.sample(\"b_Sex\", dist.Normal(0, 1).expand([2]))\n",
    "    b_sibsp = numpyro.sample(\"b_SibSp\", dist.Normal(0, 1).expand([2]))\n",
    "    b_parch = numpyro.sample(\"b_Parch\", dist.Normal(0, 1).expand([3]))\n",
    "    b_embarked = numpyro.sample(\"b_Embarked\", dist.Normal(0, 1).expand([3]))\n",
    "\n",
    "    # impute age by Title\n",
    "    isnan = np.isnan(age)\n",
    "    age_nanidx = np.nonzero(isnan)[0]\n",
    "    print('index', age_nanidx)\n",
    "    if bayesian_impute:\n",
    "        age_mu = numpyro.sample(\"age_mu\", dist.Normal(0, 1).expand([5]))\n",
    "        age_mu = age_mu[title]\n",
    "        age_sigma = numpyro.sample(\"age_sigma\", dist.Normal(0, 1).expand([5]))\n",
    "        age_sigma = age_sigma[title]\n",
    "        age_impute = numpyro.sample(\n",
    "            \"age_impute\",\n",
    "            dist.Normal(age_mu[age_nanidx], age_sigma[age_nanidx]).mask(False),\n",
    "        )\n",
    "        print('age impute size', age_impute.shape)\n",
    "        age = jnp.asarray(age).at[age_nanidx].set(age_impute)\n",
    "        numpyro.sample(\"age\", dist.Normal(age_mu, age_sigma), obs=age)\n",
    "    else:\n",
    "        # fill missing data by the mean of ages for each title\n",
    "        age_impute = age_mean_by_title[title][age_nanidx]\n",
    "        age = jnp.asarray(age).at[age_nanidx].set(age_impute)\n",
    "\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    b_age = numpyro.sample(\"b_Age\", dist.Normal(0, 1))\n",
    "    logits = a + b_age * age\n",
    "    logits = logits + b_title[title] + b_pclass[pclass] + b_sex[sex]\n",
    "    logits = logits + b_sibsp[sibsp] + b_parch[parch] + b_embarked[embarked]\n",
    "    numpyro.sample(\"survived\", dist.Bernoulli(logits=logits), obs=survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the model, the prior for `age` is `dist.Normal(age_mu, age_sigma)`, where the values of `age_mu` and `age_sigma` depend on `title`. Because there are missing values in `age`, we will encode those missing values in the latent parameter `age_impute`. Then we can replace `NaN` entries in `age` with the vector `age_impute`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MCMC with NUTS kernel to sample both regression coefficients and imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index [  5  17  19  26  28  29  31  32  36  42  45  46  47  48  55  64  65  76\n",
      "  77  82  87  95 101 107 109 121 126 128 140 154 158 159 166 168 176 180\n",
      " 181 185 186 196 198 201 214 223 229 235 240 241 250 256 260 264 270 274\n",
      " 277 284 295 298 300 301 303 304 306 324 330 334 335 347 351 354 358 359\n",
      " 364 367 368 375 384 388 409 410 411 413 415 420 425 428 431 444 451 454\n",
      " 457 459 464 466 468 470 475 481 485 490 495 497 502 507 511 517 522 524\n",
      " 527 531 533 538 547 552 557 560 563 564 568 573 578 584 589 593 596 598\n",
      " 601 602 611 612 613 629 633 639 643 648 650 653 656 667 669 674 680 692\n",
      " 697 709 711 718 727 732 738 739 740 760 766 768 773 776 778 783 790 792\n",
      " 793 815 825 826 828 832 837 839 846 849 859 863 868 878 888]\n",
      "age impute size (177,)\n",
      "index [  5  17  19  26  28  29  31  32  36  42  45  46  47  48  55  64  65  76\n",
      "  77  82  87  95 101 107 109 121 126 128 140 154 158 159 166 168 176 180\n",
      " 181 185 186 196 198 201 214 223 229 235 240 241 250 256 260 264 270 274\n",
      " 277 284 295 298 300 301 303 304 306 324 330 334 335 347 351 354 358 359\n",
      " 364 367 368 375 384 388 409 410 411 413 415 420 425 428 431 444 451 454\n",
      " 457 459 464 466 468 470 475 481 485 490 495 497 502 507 511 517 522 524\n",
      " 527 531 533 538 547 552 557 560 563 564 568 573 578 584 589 593 596 598\n",
      " 601 602 611 612 613 629 633 639 643 648 650 653 656 667 669 674 680 692\n",
      " 697 709 711 718 727 732 738 739 740 760 766 768 773 776 778 783 790 792\n",
      " 793 815 825 826 828 832 837 839 846 849 859 863 868 878 888]\n",
      "age impute size (177,)\n",
      "index [  5  17  19  26  28  29  31  32  36  42  45  46  47  48  55  64  65  76\n",
      "  77  82  87  95 101 107 109 121 126 128 140 154 158 159 166 168 176 180\n",
      " 181 185 186 196 198 201 214 223 229 235 240 241 250 256 260 264 270 274\n",
      " 277 284 295 298 300 301 303 304 306 324 330 334 335 347 351 354 358 359\n",
      " 364 367 368 375 384 388 409 410 411 413 415 420 425 428 431 444 451 454\n",
      " 457 459 464 466 468 470 475 481 485 490 495 497 502 507 511 517 522 524\n",
      " 527 531 533 538 547 552 557 560 563 564 568 573 578 584 589 593 596 598\n",
      " 601 602 611 612 613 629 633 639 643 648 650 653 656 667 669 674 680 692\n",
      " 697 709 711 718 727 732 738 739 740 760 766 768 773 776 778 783 790 792\n",
      " 793 815 825 826 828 832 837 839 846 849 859 863 868 878 888]\n",
      "age impute size (177,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index [  5  17  19  26  28  29  31  32  36  42  45  46  47  48  55  64  65  76\n",
      "  77  82  87  95 101 107 109 121 126 128 140 154 158 159 166 168 176 180\n",
      " 181 185 186 196 198 201 214 223 229 235 240 241 250 256 260 264 270 274\n",
      " 277 284 295 298 300 301 303 304 306 324 330 334 335 347 351 354 358 359\n",
      " 364 367 368 375 384 388 409 410 411 413 415 420 425 428 431 444 451 454\n",
      " 457 459 464 466 468 470 475 481 485 490 495 497 502 507 511 517 522 524\n",
      " 527 531 533 538 547 552 557 560 563 564 568 573 578 584 589 593 596 598\n",
      " 601 602 611 612 613 629 633 639 643 648 650 653 656 667 669 674 680 692\n",
      " 697 709 711 718 727 732 738 739 740 760 766 768 773 776 778 783 790 792\n",
      " 793 815 825 826 828 832 837 839 846 849 859 863 868 878 888]\n",
      "age impute size (177,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█| 2000/2000 [00:17<00:00, 113.11it/s, 63 steps of size 6.11e-02. a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "              a      0.12      0.83      0.12     -1.28      1.40   1077.21      1.00\n",
      "  age_impute[0]      0.20      0.81      0.20     -1.11      1.52   2068.95      1.00\n",
      "  age_impute[1]     -0.07      0.84     -0.09     -1.34      1.29   1524.15      1.00\n",
      "  age_impute[2]      0.38      0.77      0.35     -0.77      1.73   2369.57      1.00\n",
      "  age_impute[3]      0.25      0.84      0.24     -1.26      1.56   1209.11      1.00\n",
      "  age_impute[4]     -0.64      0.91     -0.62     -2.16      0.72   1417.63      1.00\n",
      "  age_impute[5]      0.21      0.88      0.20     -1.07      1.79   1612.38      1.00\n",
      "  age_impute[6]      0.45      0.84      0.45     -0.81      1.94   1532.53      1.00\n",
      "  age_impute[7]     -0.65      0.84     -0.65     -2.15      0.66   1795.94      1.00\n",
      "  age_impute[8]     -0.14      0.90     -0.16     -1.49      1.49   1931.31      1.00\n",
      "  age_impute[9]      0.24      0.85      0.23     -1.19      1.65   1669.16      1.00\n",
      " age_impute[10]      0.21      0.90      0.24     -1.32      1.52   2061.80      1.00\n",
      " age_impute[11]      0.19      0.92      0.21     -1.22      1.75   1970.72      1.00\n",
      " age_impute[12]     -0.64      0.88     -0.65     -2.04      0.81   1672.25      1.00\n",
      " age_impute[13]      0.20      0.83      0.19     -1.15      1.55   1356.76      1.00\n",
      " age_impute[14]      0.04      0.93      0.02     -1.44      1.63   1380.80      1.00\n",
      " age_impute[15]      0.37      0.95      0.37     -1.05      1.93   1783.96      1.00\n",
      " age_impute[16]     -1.74      0.26     -1.75     -2.15     -1.34   1361.85      1.00\n",
      " age_impute[17]      0.21      0.90      0.25     -1.20      1.73   1641.08      1.00\n",
      " age_impute[18]      0.19      0.92      0.19     -1.27      1.60   2158.01      1.00\n",
      " age_impute[19]     -0.67      0.87     -0.65     -1.93      0.92   1981.98      1.00\n",
      " age_impute[20]      0.24      0.88      0.29     -1.25      1.64   1908.19      1.00\n",
      " age_impute[21]      0.22      0.88      0.23     -1.27      1.60   1552.13      1.00\n",
      " age_impute[22]      0.19      0.87      0.17     -1.18      1.62   1628.36      1.00\n",
      " age_impute[23]     -0.17      0.86     -0.18     -1.61      1.20   1559.84      1.00\n",
      " age_impute[24]     -0.70      0.90     -0.69     -2.18      0.63   1419.94      1.00\n",
      " age_impute[25]      0.21      0.86      0.21     -1.24      1.60   1810.98      1.00\n",
      " age_impute[26]      0.23      0.87      0.24     -1.30      1.58   1692.53      1.00\n",
      " age_impute[27]     -0.69      0.89     -0.73     -2.07      0.81   1517.49      1.00\n",
      " age_impute[28]      0.59      0.78      0.61     -0.80      1.75   1748.61      1.00\n",
      " age_impute[29]      0.19      0.89      0.17     -1.28      1.60   1301.08      1.00\n",
      " age_impute[30]      0.23      0.85      0.23     -1.15      1.58   1283.04      1.00\n",
      " age_impute[31]     -1.72      0.26     -1.71     -2.13     -1.25   1795.51      1.00\n",
      " age_impute[32]      0.42      0.77      0.42     -0.76      1.67   1683.20      1.00\n",
      " age_impute[33]      0.33      0.92      0.32     -1.22      1.79   1644.80      1.00\n",
      " age_impute[34]     -1.72      0.26     -1.72     -2.11     -1.28   1260.32      1.00\n",
      " age_impute[35]     -0.46      0.91     -0.46     -1.86      1.09   1333.32      1.00\n",
      " age_impute[36]      0.30      0.85      0.28     -1.00      1.75   1270.61      1.00\n",
      " age_impute[37]      0.34      0.90      0.33     -1.19      1.81   1196.33      1.00\n",
      " age_impute[38]      0.34      0.75      0.31     -0.99      1.45   2255.04      1.00\n",
      " age_impute[39]      0.21      0.93      0.20     -1.34      1.71   1638.85      1.00\n",
      " age_impute[40]     -0.68      0.89     -0.68     -2.02      0.86   1580.80      1.00\n",
      " age_impute[41]      0.17      0.88      0.16     -1.38      1.39   1409.19      1.00\n",
      " age_impute[42]      0.23      0.82      0.26     -1.11      1.52   1503.67      1.00\n",
      " age_impute[43]      0.23      0.84      0.24     -1.13      1.61   1623.51      1.00\n",
      " age_impute[44]     -0.41      0.84     -0.40     -1.76      0.91    905.51      1.00\n",
      " age_impute[45]     -0.34      0.89     -0.33     -1.79      1.15   2001.96      1.00\n",
      " age_impute[46]     -0.33      0.94     -0.31     -1.99      1.13   2338.45      1.00\n",
      " age_impute[47]     -0.70      0.84     -0.70     -2.03      0.73   1727.59      1.00\n",
      " age_impute[48]      0.22      0.85      0.24     -1.12      1.62   1550.20      1.00\n",
      " age_impute[49]      0.42      0.82      0.41     -0.93      1.71   1410.64      1.00\n",
      " age_impute[50]      0.25      0.86      0.25     -1.21      1.60   1457.90      1.00\n",
      " age_impute[51]     -0.29      0.92     -0.31     -1.78      1.19   1800.14      1.00\n",
      " age_impute[52]      0.35      0.85      0.34     -0.95      1.84   1423.19      1.00\n",
      " age_impute[53]     -0.69      0.87     -0.67     -1.94      0.94   1538.61      1.00\n",
      " age_impute[54]      0.25      0.89      0.21     -1.09      1.73   1943.46      1.00\n",
      " age_impute[55]      0.35      0.89      0.35     -0.94      1.93   2166.49      1.00\n",
      " age_impute[56]      0.38      0.87      0.40     -1.06      1.69   2083.44      1.00\n",
      " age_impute[57]     -0.00      0.90      0.01     -1.57      1.34   1682.25      1.00\n",
      " age_impute[58]     -0.69      0.91     -0.67     -2.13      0.78   1990.78      1.00\n",
      " age_impute[59]     -0.14      0.84     -0.15     -1.60      1.17   1164.78      1.00\n",
      " age_impute[60]     -0.59      0.94     -0.60     -2.14      0.98   1280.90      1.00\n",
      " age_impute[61]      0.25      0.91      0.27     -1.31      1.66   1795.33      1.00\n",
      " age_impute[62]     -0.55      0.92     -0.57     -1.96      1.01   1039.52      1.00\n",
      " age_impute[63]      0.20      0.88      0.17     -1.26      1.66   1633.95      1.00\n",
      " age_impute[64]     -0.66      0.87     -0.68     -1.96      0.80   1392.92      1.00\n",
      " age_impute[65]      0.43      0.80      0.45     -0.94      1.63   1324.15      1.00\n",
      " age_impute[66]      0.22      0.93      0.20     -1.36      1.65   2154.25      1.00\n",
      " age_impute[67]      0.32      0.76      0.33     -1.10      1.39   1294.66      1.00\n",
      " age_impute[68]      0.31      0.85      0.30     -1.07      1.65   2024.62      1.00\n",
      " age_impute[69]      0.26      0.91      0.25     -1.19      1.82   1564.63      1.00\n",
      " age_impute[70]     -0.67      0.85     -0.69     -1.94      0.79   1595.11      1.00\n",
      " age_impute[71]     -0.69      0.90     -0.67     -2.08      0.84   1401.66      1.00\n",
      " age_impute[72]      0.22      0.87      0.24     -1.15      1.63   1840.91      1.00\n",
      " age_impute[73]      0.33      0.72      0.35     -0.71      1.60   1397.59      1.00\n",
      " age_impute[74]     -0.66      0.86     -0.66     -2.21      0.67   2035.29      1.00\n",
      " age_impute[75]      0.41      0.80      0.41     -1.03      1.58    953.22      1.00\n",
      " age_impute[76]      0.20      0.89      0.20     -1.25      1.70   1482.39      1.00\n",
      " age_impute[77]      0.21      0.81      0.19     -1.09      1.60   1855.07      1.00\n",
      " age_impute[78]     -0.36      0.87     -0.36     -1.86      0.96   1451.07      1.00\n",
      " age_impute[79]      0.20      0.83      0.19     -1.22      1.42   1780.94      1.00\n",
      " age_impute[80]      0.24      0.84      0.24     -1.12      1.67   1862.92      1.00\n",
      " age_impute[81]      0.30      0.88      0.32     -1.12      1.75   1773.93      1.00\n",
      " age_impute[82]      0.60      0.81      0.58     -0.81      1.86   1856.53      1.00\n",
      " age_impute[83]      0.23      0.90      0.26     -1.13      1.75   1387.58      1.00\n",
      " age_impute[84]      0.22      0.90      0.21     -1.25      1.67   1422.94      1.00\n",
      " age_impute[85]      0.23      0.93      0.23     -1.24      1.80   1380.63      1.00\n",
      " age_impute[86]      0.32      0.81      0.34     -0.86      1.77   1527.15      1.00\n",
      " age_impute[87]     -0.11      0.85     -0.09     -1.34      1.33   1837.79      1.00\n",
      " age_impute[88]      0.20      0.93      0.23     -1.35      1.69   1219.81      1.00\n",
      " age_impute[89]      0.24      0.88      0.21     -1.17      1.66   2921.76      1.00\n",
      " age_impute[90]      0.40      0.86      0.45     -0.93      1.90   1506.34      1.00\n",
      " age_impute[91]      0.21      0.87      0.22     -1.13      1.66   2021.57      1.00\n",
      " age_impute[92]      0.21      0.81      0.18     -1.05      1.58   2061.76      1.00\n",
      " age_impute[93]      0.22      0.88      0.22     -1.31      1.54   1588.46      1.00\n",
      " age_impute[94]      0.22      0.88      0.20     -1.05      1.80    984.99      1.00\n",
      " age_impute[95]      0.22      0.87      0.23     -1.34      1.49   1315.47      1.00\n",
      " age_impute[96]      0.31      0.84      0.29     -1.09      1.65   1780.81      1.00\n",
      " age_impute[97]      0.22      0.87      0.22     -1.10      1.69   1808.20      1.00\n",
      " age_impute[98]     -0.36      0.91     -0.38     -1.85      1.18   1127.96      1.00\n",
      " age_impute[99]      0.17      0.88      0.15     -1.29      1.60   1867.76      1.00\n",
      "age_impute[100]      0.27      0.86      0.31     -1.05      1.71   1452.17      1.00\n",
      "age_impute[101]      0.24      0.88      0.23     -1.24      1.55   1658.81      1.00\n",
      "age_impute[102]     -0.28      0.87     -0.29     -1.71      1.13   1536.71      1.00\n",
      "age_impute[103]      0.01      0.90      0.03     -1.50      1.37   1375.40      1.00\n",
      "age_impute[104]      0.21      0.88      0.19     -1.25      1.67   1373.33      1.00\n",
      "age_impute[105]      0.25      0.92      0.24     -1.16      1.77   1619.34      1.00\n",
      "age_impute[106]      0.22      0.84      0.23     -1.12      1.65   1904.00      1.00\n",
      "age_impute[107]      0.21      0.84      0.23     -1.06      1.56   1980.59      1.00\n",
      "age_impute[108]      0.32      0.87      0.30     -0.99      1.82   2156.05      1.00\n",
      "age_impute[109]      0.23      0.85      0.22     -1.07      1.70   1453.10      1.00\n",
      "age_impute[110]      0.32      0.80      0.33     -0.93      1.65   1571.30      1.00\n",
      "age_impute[111]      0.22      0.86      0.18     -1.04      1.78   1586.13      1.00\n",
      "age_impute[112]     -0.03      0.91     -0.02     -1.41      1.50   1794.38      1.00\n",
      "age_impute[113]      0.25      0.86      0.26     -1.12      1.76   1592.25      1.00\n",
      "age_impute[114]      0.37      0.84      0.35     -1.14      1.55   1457.25      1.00\n",
      "age_impute[115]      0.25      0.94      0.26     -1.36      1.79   1480.27      1.00\n",
      "age_impute[116]      0.21      0.84      0.21     -1.10      1.62   1911.79      1.00\n",
      "age_impute[117]     -0.33      0.95     -0.33     -1.87      1.25   1985.91      1.00\n",
      "age_impute[118]      0.21      0.87      0.20     -1.13      1.70   1497.07      1.00\n",
      "age_impute[119]     -0.69      0.91     -0.72     -2.05      0.95   2205.72      1.00\n",
      "age_impute[120]      0.64      0.82      0.65     -0.72      1.91   1121.63      1.00\n",
      "age_impute[121]      0.27      0.91      0.25     -1.18      1.77   1737.29      1.00\n",
      "age_impute[122]      0.18      0.87      0.19     -1.25      1.56   1809.28      1.00\n",
      "age_impute[123]     -0.39      0.88     -0.40     -1.72      1.14   1147.96      1.00\n",
      "age_impute[124]     -0.62      0.95     -0.63     -2.12      0.96   1767.57      1.00\n",
      "age_impute[125]      0.23      0.89      0.23     -1.25      1.65   2186.08      1.00\n",
      "age_impute[126]      0.18      0.90      0.17     -1.22      1.67   1634.76      1.00\n",
      "age_impute[127]      0.33      0.84      0.35     -1.14      1.67   1520.56      1.00\n",
      "age_impute[128]      0.24      0.86      0.25     -1.06      1.67   1575.79      1.00\n",
      "age_impute[129]     -0.70      0.86     -0.67     -2.09      0.72   1639.24      1.00\n",
      "age_impute[130]      0.22      0.89      0.23     -1.35      1.50   1856.40      1.00\n",
      "age_impute[131]      0.21      0.87      0.21     -1.24      1.64   1194.04      1.00\n",
      "age_impute[132]      0.32      0.85      0.32     -1.05      1.63   1519.42      1.00\n",
      "age_impute[133]      0.17      0.84      0.15     -1.24      1.46   1326.45      1.00\n",
      "age_impute[134]     -0.13      0.92     -0.16     -1.60      1.32   1706.13      1.00\n",
      "age_impute[135]      0.17      0.85      0.17     -1.30      1.47   1403.45      1.00\n",
      "age_impute[136]      0.17      0.92      0.18     -1.33      1.73   2110.28      1.00\n",
      "age_impute[137]     -0.71      0.91     -0.72     -2.16      0.86   1341.82      1.00\n",
      "age_impute[138]      0.19      0.90      0.19     -1.22      1.68   1396.97      1.00\n",
      "age_impute[139]      0.24      0.91      0.25     -1.17      1.80   1390.31      1.00\n",
      "age_impute[140]      0.40      0.80      0.40     -0.94      1.61   1603.37      1.00\n",
      "age_impute[141]      0.26      0.83      0.26     -0.96      1.73   1391.53      1.00\n",
      "age_impute[142]     -0.28      0.89     -0.29     -1.83      1.07   1498.55      1.00\n",
      "age_impute[143]     -0.13      0.93     -0.13     -1.70      1.33   1932.99      1.00\n",
      "age_impute[144]     -0.66      0.88     -0.63     -2.17      0.70   2115.65      1.00\n",
      "age_impute[145]     -1.74      0.25     -1.74     -2.13     -1.31   1798.09      1.00\n",
      "age_impute[146]      0.40      0.85      0.39     -0.91      1.85   1641.30      1.00\n",
      "age_impute[147]      0.23      0.86      0.23     -1.13      1.65   2202.73      1.00\n",
      "age_impute[148]     -0.68      0.87     -0.68     -2.18      0.67   2183.41      1.00\n",
      "age_impute[149]      0.27      0.87      0.27     -1.20      1.66   1834.75      1.00\n",
      "age_impute[150]      0.21      0.91      0.22     -1.25      1.69   1736.91      1.00\n",
      "age_impute[151]      0.24      0.85      0.25     -1.14      1.64   1454.76      1.00\n",
      "age_impute[152]      0.04      0.85      0.05     -1.34      1.35   1762.58      1.00\n",
      "age_impute[153]      0.17      0.89      0.15     -1.29      1.56   2204.59      1.00\n",
      "age_impute[154]      1.06      0.93      1.05     -0.65      2.45   1306.12      1.00\n",
      "age_impute[155]      0.21      0.86      0.19     -1.09      1.66   1646.97      1.00\n",
      "age_impute[156]      0.24      0.97      0.24     -1.37      1.77   1928.28      1.00\n",
      "age_impute[157]      0.21      0.85      0.22     -1.33      1.51   1671.81      1.00\n",
      "age_impute[158]      0.23      0.88      0.24     -1.18      1.67   1487.62      1.00\n",
      "age_impute[159]      0.19      0.85      0.19     -1.34      1.41   2090.18      1.00\n",
      "age_impute[160]      0.25      0.89      0.27     -1.35      1.61   1180.92      1.00\n",
      "age_impute[161]     -0.46      0.89     -0.44     -1.91      1.05   1845.46      1.00\n",
      "age_impute[162]      0.40      0.91      0.41     -1.05      1.85   1906.21      1.00\n",
      "age_impute[163]      0.34      0.91      0.38     -1.15      1.78   2112.59      1.00\n",
      "age_impute[164]      0.20      0.92      0.18     -1.27      1.63   1600.24      1.00\n",
      "age_impute[165]      0.22      0.84      0.17     -1.05      1.66   1441.76      1.00\n",
      "age_impute[166]     -0.13      0.90     -0.15     -1.58      1.28   1461.65      1.00\n",
      "age_impute[167]      0.22      0.89      0.21     -1.14      1.79   1495.05      1.00\n",
      "age_impute[168]      0.20      0.91      0.17     -1.14      1.91   1172.42      1.00\n",
      "age_impute[169]      0.07      0.89      0.07     -1.39      1.49   2150.51      1.00\n",
      "age_impute[170]      0.22      0.90      0.23     -1.13      1.84   1328.59      1.00\n",
      "age_impute[171]      0.42      0.79      0.43     -0.77      1.85   1600.95      1.00\n",
      "age_impute[172]      0.22      0.88      0.21     -1.35      1.52   2480.77      1.00\n",
      "age_impute[173]     -0.43      0.88     -0.41     -1.90      1.03   1367.70      1.00\n",
      "age_impute[174]      0.19      0.83      0.22     -1.13      1.60   1926.75      1.00\n",
      "age_impute[175]      0.19      0.86      0.21     -1.34      1.57   2114.39      1.00\n",
      "age_impute[176]     -0.43      0.89     -0.44     -1.91      1.00   1637.76      1.00\n",
      "      age_mu[0]      0.19      0.04      0.19      0.12      0.26    872.02      1.00\n",
      "      age_mu[1]     -0.54      0.07     -0.54     -0.67     -0.42   1176.73      1.00\n",
      "      age_mu[2]      0.42      0.08      0.42      0.30      0.55   1597.65      1.00\n",
      "      age_mu[3]     -1.73      0.04     -1.73     -1.79     -1.65   1644.34      1.00\n",
      "      age_mu[4]      0.85      0.17      0.85      0.61      1.15   1322.91      1.00\n",
      "   age_sigma[0]      0.88      0.03      0.88      0.83      0.93   1025.82      1.00\n",
      "   age_sigma[1]      0.90      0.06      0.90      0.80      0.99   1182.11      1.00\n",
      "   age_sigma[2]      0.79      0.05      0.79      0.71      0.87    908.52      1.00\n",
      "   age_sigma[3]      0.26      0.03      0.25      0.21      0.31    950.05      1.00\n",
      "   age_sigma[4]      0.93      0.13      0.92      0.73      1.15   1318.71      1.00\n",
      "          b_Age     -0.45      0.13     -0.44     -0.69     -0.25    825.01      1.00\n",
      "  b_Embarked[0]     -0.27      0.58     -0.29     -1.20      0.67    518.23      1.00\n",
      "  b_Embarked[1]      0.30      0.60      0.28     -0.71      1.25    541.23      1.00\n",
      "  b_Embarked[2]      0.05      0.61      0.04     -0.92      1.04    521.83      1.00\n",
      "     b_Parch[0]      0.44      0.56      0.47     -0.44      1.36    396.95      1.02\n",
      "     b_Parch[1]      0.11      0.58      0.12     -0.83      1.05    423.39      1.02\n",
      "     b_Parch[2]     -0.50      0.58     -0.50     -1.47      0.41    400.04      1.01\n",
      "    b_Pclass[0]      1.22      0.57      1.24      0.32      2.16    483.07      1.00\n",
      "    b_Pclass[1]      0.06      0.58      0.10     -0.89      1.03    465.20      1.00\n",
      "    b_Pclass[2]     -1.18      0.56     -1.17     -2.15     -0.31    465.98      1.00\n",
      "       b_Sex[0]      1.14      0.74      1.18     -0.12      2.22    715.44      1.00\n",
      "       b_Sex[1]     -1.05      0.73     -1.02     -2.13      0.21    866.70      1.00\n",
      "     b_SibSp[0]      0.28      0.66      0.26     -0.82      1.34    658.17      1.00\n",
      "     b_SibSp[1]     -0.17      0.66     -0.19     -1.23      0.86    651.20      1.00\n",
      "     b_Title[0]     -0.94      0.53     -0.95     -1.84     -0.09    560.04      1.00\n",
      "     b_Title[1]     -0.33      0.62     -0.34     -1.34      0.65    639.18      1.00\n",
      "     b_Title[2]      0.54      0.62      0.55     -0.51      1.51    462.03      1.00\n",
      "     b_Title[3]      1.48      0.59      1.47      0.54      2.44    728.45      1.00\n",
      "     b_Title[4]     -0.68      0.58     -0.67     -1.60      0.29    639.47      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(NUTS(model), num_warmup=1000, num_samples=1000)\n",
    "mcmc.run(random.PRNGKey(0), **data, survived=survived)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double check that the assumption \"age is correlated with title\" is reasonable, let's look at the infered age by title. Recall that we performed standarization on `age`, so here we need to scale back to original domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mr.': DeviceArray(32.42303, dtype=float32),\n",
       " 'Miss.': DeviceArray(21.783125, dtype=float32),\n",
       " 'Mrs.': DeviceArray(35.86772, dtype=float32),\n",
       " 'Master.': DeviceArray(4.6148586, dtype=float32),\n",
       " 'Misc.': DeviceArray(42.061874, dtype=float32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_by_title = age_mean + age_std * mcmc.get_samples()[\"age_mu\"].mean(axis=0)\n",
    "dict(zip(title_cat.categories, age_by_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The infered result confirms our assumption that `Age` is correlated with `Title`:\n",
    "\n",
    "+ those with `Master.` title has pretty small age (in other words, they are children in the ship) comparing to the other groups,\n",
    "+ those with `Mrs.` title have larger age than those with `Miss.` title (in average).\n",
    "\n",
    "We can also see that the result is similar to the actual statistical mean of `Age` given `Title` in our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Master.     4.574167\n",
       "Misc.      42.384615\n",
       "Miss.      21.773973\n",
       "Mr.        32.368090\n",
       "Mrs.       35.898148\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(\"Title\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, we have many information about the regression coefficients together with imputed values and their uncertainties. Let's inspect those results a bit:\n",
    "\n",
    "+ The mean value `-0.44` of `b_Age` implies that those with smaller ages have better chance to survive.\n",
    "+ The mean value `(1.11, -1.07)` of `b_Sex` implies that female passengers have higher chance to survive than male passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPyro, we can use [Predictive](http://num.pyro.ai/en/stable/utilities.html#numpyro.infer.util.Predictive) utility for making predictions from posterior samples. Let's check how well the model performs on the training dataset. For simplicity, we will get a `survived` prediction for each posterior sample and perform the majority rule on the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index [  5  17  19  26  28  29  31  32  36  42  45  46  47  48  55  64  65  76\n",
      "  77  82  87  95 101 107 109 121 126 128 140 154 158 159 166 168 176 180\n",
      " 181 185 186 196 198 201 214 223 229 235 240 241 250 256 260 264 270 274\n",
      " 277 284 295 298 300 301 303 304 306 324 330 334 335 347 351 354 358 359\n",
      " 364 367 368 375 384 388 409 410 411 413 415 420 425 428 431 444 451 454\n",
      " 457 459 464 466 468 470 475 481 485 490 495 497 502 507 511 517 522 524\n",
      " 527 531 533 538 547 552 557 560 563 564 568 573 578 584 589 593 596 598\n",
      " 601 602 611 612 613 629 633 639 643 648 650 653 656 667 669 674 680 692\n",
      " 697 709 711 718 727 732 738 739 740 760 766 768 773 776 778 783 790 792\n",
      " 793 815 825 826 828 832 837 839 846 849 859 863 868 878 888]\n",
      "age impute size (177,)\n",
      "Accuracy: 0.8249158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.874317</td>\n",
       "      <td>0.201754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158470</td>\n",
       "      <td>0.745614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict         0         1\n",
       "actual                     \n",
       "0        0.874317  0.201754\n",
       "1        0.158470  0.745614"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior = mcmc.get_samples()\n",
    "survived_pred = Predictive(model, posterior)(random.PRNGKey(1), **data)[\"survived\"]\n",
    "survived_pred = (survived_pred.mean(axis=0) >= 0.5).astype(jnp.uint8)\n",
    "print(\"Accuracy:\", (survived_pred == survived).sum() / survived.shape[0])\n",
    "confusion_matrix = pd.crosstab(\n",
    "    pd.Series(survived, name=\"actual\"), pd.Series(survived_pred, name=\"predict\")\n",
    ")\n",
    "confusion_matrix / confusion_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good result using a simple logistic regression model. Let's see how the model performs if we don't use Bayesian imputation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** add predictions on \"new data\" to demonstrate the problem with imputing for new missing data ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train_df2 = train_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862    48.0\n",
       "223     NaN\n",
       "84     17.0\n",
       "680     NaN\n",
       "535     7.0\n",
       "       ... \n",
       "715    19.0\n",
       "767    30.5\n",
       "72     21.0\n",
       "235     NaN\n",
       "37     21.0\n",
       "Name: Age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/593h0xvn7r3cvdwpbnnwrky00000gn/T/ipykernel_59995/1377674010.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age[0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "title_cat2 = pd.CategoricalDtype(\n",
    "    categories=[\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\", \"Misc.\"], ordered=True\n",
    ")\n",
    "embarked_cat2 = pd.CategoricalDtype(categories=[\"S\", \"C\", \"Q\"], ordered=True)\n",
    "age_mean2, age_std2 = train_df2.Age.mean(), train_df2.Age.std()\n",
    "# sprinkle in more missing for age\n",
    "age = train_df2.Age\n",
    "# add a new missing value:\n",
    "age[0] = np.nan\n",
    "data2 = dict(\n",
    "    age=age.pipe(lambda x: (x - age_mean2) / age_std2).values,\n",
    "    pclass=train_df2.Pclass.values - 1,\n",
    "    title=train_df2.Title.astype(title_cat2).cat.codes.values,\n",
    "    sex=(train_df2.Sex == \"male\").astype(int).values,\n",
    "    sibsp=train_df2.SibSp.values,\n",
    "    parch=train_df2.Parch.values,\n",
    "    embarked=train_df2.Embarked.astype(embarked_cat2).cat.codes.values,\n",
    ")\n",
    "survived2 = train_df2.Survived.values\n",
    "# compute the age mean for each title\n",
    "age_notnan2 = data2[\"age\"][jnp.isfinite(data2[\"age\"])]\n",
    "title_notnan2 = data2[\"title\"][jnp.isfinite(data2[\"age\"])]\n",
    "age_mean_by_title2 = jnp.stack([age_notnan2[title_notnan2 == i].mean() for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index [  1   3   9  13  14  31  37  50  60  61  73  77  81  82  86  87  91  93\n",
      "  94  97  99 100 102 122 128 129 143 144 147 154 167 175 176 179 186 188\n",
      " 190 192 196 202 208 216 220 221 224 235 236 237 239 261 262 270 272 287\n",
      " 294 297 299 307 310 311 313 327 328 336 338 339 352 356 361 363 366 379\n",
      " 384 395 397 399 406 409 417 419 421 423 426 427 432 433 438 443 444 455\n",
      " 456 460 461 464 474 487 492 497 500 504 514 523 527 531 541 542 544 547\n",
      " 552 565 568 569 577 586 593 594 605 606 613 615 618 620 631 639 643 644\n",
      " 651 661 663 664 665 667 669 671 675 681 683 684 687 690 691 695 699 702\n",
      " 719 723 727 733 735 738 739 744 753 774 782 791 797 798 802 805 806 813\n",
      " 821 822 824 825 827 832 835 836 840 845 846 848 850 870 872 889]\n",
      "age impute size (177,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: (177,) and requested shape (178,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rx/593h0xvn7r3cvdwpbnnwrky00000gn/T/ipykernel_59995/448896184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msurvived_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msurvived_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurvived_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurvived_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msurvived\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m confusion_matrix = pd.crosstab(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, rng_key, *args, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \"\"\"\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# batch over parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36m_call_with_params\u001b[0;34m(self, rng_key, params, args, kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m             )\n\u001b[1;32m    937\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubstitute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         return _predictive(\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36m_predictive\u001b[0;34m(rng_key, model, posterior_samples, batch_shape, return_sites, infer_discrete, parallel, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mrng_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     return soft_vmap(\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0msingle_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/util.py\u001b[0m in \u001b[0;36msoft_vmap\u001b[0;34m(fn, xs, batch_ndims, chunk_size)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_chunks\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0mmap_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chunks\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     ys = tree_map(\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36msingle_prediction\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    747\u001b[0m             )\n\u001b[1;32m    748\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             model_trace = trace(\n\u001b[0m\u001b[1;32m    750\u001b[0m                 \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             ).get_trace(*model_args, **model_kwargs)\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/handlers.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rx/593h0xvn7r3cvdwpbnnwrky00000gn/T/ipykernel_59995/2005743403.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(age, pclass, title, sex, sibsp, parch, embarked, survived, bayesian_impute)\u001b[0m\n\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'age impute size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_impute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage_nanidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_impute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mnumpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, values, indices_are_sorted, unique_indices, mode)\u001b[0m\n\u001b[1;32m   6936\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6937\u001b[0m     \"\"\"\n\u001b[0;32m-> 6938\u001b[0;31m     return scatter._scatter_update(self.array, self.index, values, lax.scatter,\n\u001b[0m\u001b[1;32m   6939\u001b[0m                                    \u001b[0mindices_are_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices_are_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m                                    unique_indices=unique_indices, mode=mode)\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/jax/_src/ops/scatter.py\u001b[0m in \u001b[0;36m_scatter_update\u001b[0;34m(x, idx, y, scatter_op, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;31m# is more or less a transpose of the gather equivalent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   return _scatter_impl(x, y, scatter_op, treedef, static_idx, dynamic_idx,\n\u001b[0m\u001b[1;32m     70\u001b[0m                        \u001b[0mindices_are_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                        normalize_indices)\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/jax/_src/ops/scatter.py\u001b[0m in \u001b[0;36m_scatter_impl\u001b[0;34m(x, y, scatter_op, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;31m# Broadcast `y` to the slice output shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# Collapse any `None`/`jnp.newaxis` dimensions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ab_test_script/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(arr, shape)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnlead\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompatible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Incompatible shapes for broadcasting: {} and requested shape {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     diff, = np.where(tuple(not core.symbolic_equal_dim(arr_d, shape_d)\n\u001b[1;32m   2259\u001b[0m                            for arr_d, shape_d in safe_zip(arr_shape, shape_tail)))\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (177,) and requested shape (178,)"
     ]
    }
   ],
   "source": [
    "posterior = mcmc.get_samples()\n",
    "survived_pred = Predictive(model, posterior)(random.PRNGKey(1), **data2)[\"survived\"]\n",
    "survived_pred = (survived_pred.mean(axis=0) >= 0.5).astype(jnp.uint8)\n",
    "print(\"Accuracy:\", (survived_pred == survived).sum() / survived.shape[0])\n",
    "confusion_matrix = pd.crosstab(\n",
    "    pd.Series(survived2, name=\"actual\"), pd.Series(survived_pred, name=\"predict\")\n",
    ")\n",
    "confusion_matrix / confusion_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.run(random.PRNGKey(2), **data, survived=survived, bayesian_impute=False)\n",
    "posterior_1 = mcmc.get_samples()\n",
    "survived_pred_1 = Predictive(model, posterior_1)(random.PRNGKey(2), **data)[\"survived\"]\n",
    "survived_pred_1 = (survived_pred_1.mean(axis=0) >= 0.5).astype(jnp.uint8)\n",
    "print(\"Accuracy:\", (survived_pred_1 == survived).sum() / survived.shape[0])\n",
    "confusion_matrix = pd.crosstab(\n",
    "    pd.Series(survived, name=\"actual\"), pd.Series(survived_pred_1, name=\"predict\")\n",
    ")\n",
    "confusion_matrix / confusion_matrix.sum(axis=1)\n",
    "confusion_matrix = pd.crosstab(\n",
    "    pd.Series(survived, name=\"actual\"), pd.Series(survived_pred_1, name=\"predict\")\n",
    ")\n",
    "confusion_matrix / confusion_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Bayesian imputation does a little bit better here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark.** When using `posterior` samples to perform prediction on the new data, we need to marginalize out `age_impute` because those imputing values are specific to the training data:\n",
    "```python\n",
    "posterior.pop(\"age_impute\")\n",
    "survived_pred = Predictive(model, posterior)(random.PRNGKey(3), **new_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. McElreath, R. (2016). Statistical Rethinking: A Bayesian Course with Examples in R and Stan.\n",
    "2. Kaggle competition: [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ab_test_script]",
   "language": "python",
   "name": "conda-env-ab_test_script-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
